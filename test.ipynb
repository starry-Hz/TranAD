{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:05\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "start = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "start_dt = datetime.strptime(start, \"%Y-%m-%d %H:%M:%S\")\n",
    "\t\n",
    "time.sleep(5)\n",
    "end = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "end_dt = datetime.strptime(end, \"%Y-%m-%d %H:%M:%S\")\n",
    "print(end_dt-start_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WADI数据集处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (20000, 127), test.shape: (17280, 127), label.shape: (172800, 127)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "def convertNumpy(df):\n",
    "    # 每隔10取一行数据，从第四列开始取值\n",
    "    x = df[df.columns[2:]].values[::10, :]\n",
    "    # print(f\"x.shape: {x.shape}\")\n",
    "    return (x - x.min(0)) / (x.ptp(0) + 1e-4)  # 归一化，x.ptp(0) = x.max(0) - x.min(0)，添加1e-4防止除0\n",
    "\n",
    "def convertNumpy_4(df):\n",
    "    batch_num = 4\n",
    "    # Select every 10th row starting from the 4th row\n",
    "    df = df.iloc[batch_num::10, :]\n",
    "    # Select columns starting from the 4th column\n",
    "    x = df.iloc[:, :]\n",
    "    min_vals = x.min(axis=0)\n",
    "    max_vals = x.max(axis=0)\n",
    "    batch_data = (x - min_vals) / (max_vals - min_vals + 1e-4)\n",
    "    # print(f\"batch_data.shape: {batch_data.shape}\")\n",
    "    return batch_data  # Normalized data\n",
    "\n",
    "def normalize3(a, min_a = None, max_a = None):\n",
    "\tif min_a is None: min_a, max_a = np.min(a, axis = 0), np.max(a, axis = 0)\n",
    "\treturn (a - min_a) / (max_a - min_a + 0.0001), min_a, max_a\n",
    "dataset_folder = 'data/WADI/2019'\n",
    "# 训练数据,跳过前1000行,读取20万行\n",
    "train_df = pd.read_csv(os.path.join(dataset_folder, 'WADI_14days_new.csv'),index_col=0,nrows=2e5)\n",
    "test_df = pd.read_csv(os.path.join(dataset_folder, 'WADI_attackdataLABLE.csv'),header=1,index_col=0).iloc[:172800,2:]\n",
    "train = train_df.copy(deep=True)\n",
    "test = test_df.copy(deep=True)\n",
    "label = test['Attack LABLE (1:No Attack, -1:Attack)'].replace({1: 0, -1: 1}).copy(deep = True)\n",
    "test = test_df.drop('Attack LABLE (1:No Attack, -1:Attack)', axis=1).copy(deep = True)\n",
    "# 将label 拓展成与test相同的维度\n",
    "label = pd.concat([label]*len(test.columns), axis=1)\n",
    "train.dropna(how='all', inplace=True); test.dropna(how='all', inplace=True)\t# 删除全为NaN的行\n",
    "train.fillna(0, inplace=True); test.fillna(0, inplace=True)\t# 将NaN替换为0\n",
    "\n",
    "\n",
    "\n",
    "train = convertNumpy(train)\n",
    "test = convertNumpy_4(test)\n",
    "labels = convertNumpy_4(label)\n",
    "\n",
    "\n",
    "_, min_a, max_a = normalize3(np.concatenate((train, test), axis=0))\n",
    "train, _, _ = normalize3(train, min_a, max_a)\n",
    "test, _, _ = normalize3(test, min_a, max_a)\n",
    "\n",
    "output_folder = 'processed/WADI1'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "print(f\"train.shape: {train.shape}, test.shape: {test.shape}, label.shape: {label.shape}\")\n",
    "for file in ['train', 'test', 'labels']:\n",
    "\tnp.save(os.path.join(output_folder, f'{file}.npy'), eval(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWaT数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (20000, 51), test.shape: (7499, 51), labels.shape: (7499, 51)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def convertNumpy(df):\n",
    "    # 每隔10取一行数据，从第二列开始取值\n",
    "    x = df[df.columns[1:]].values[::10, :]\n",
    "    # print(f\"x.shape: {x.shape}\")\n",
    "    min_vals = x.min(axis=0)\n",
    "    max_vals = x.max(axis=0)\n",
    "    return (x - min_vals) / (max_vals - min_vals + 1e-4)  # 归一化，x.ptp(0) = x.max(0) - x.min(0)，添加1e-4防止除0\n",
    "def convertNumpy_4(df):\n",
    "    batch_num = 20\n",
    "    # Select every 10th row starting from the 4th row\n",
    "    df = df.iloc[batch_num::60, :]\n",
    "    # Select columns starting from the 4th column\n",
    "    x = df.iloc[:, :]\n",
    "    min_vals = x.min(axis=0)\n",
    "    max_vals = x.max(axis=0)\n",
    "    batch_data = (x - min_vals) / (max_vals - min_vals + 1e-4)\n",
    "    # print(f\"batch_data.shape: {batch_data.shape}\")\n",
    "    return batch_data  # Normalized data\n",
    "def normalize3(a, min_a = None, max_a = None):\n",
    "\tif min_a is None: min_a, max_a = np.min(a, axis = 0), np.max(a, axis = 0)\n",
    "\treturn (a - min_a) / (max_a - min_a + 0.0001), min_a, max_a\n",
    "# 读取数据\n",
    "dataset_folder = 'data/SWaT'\n",
    "train_df = pd.read_csv(os.path.join(dataset_folder, 'SWaT_Dataset_Attack_v0.csv'), nrows=int(2e5))\n",
    "test_df = pd.read_csv(os.path.join(dataset_folder, 'SWaT_Dataset_Attack_v0.csv'))\n",
    "# 处理训练数据和测试数据\n",
    "train = train_df.copy(deep=True).iloc[:, :-1]\n",
    "test = test_df.copy(deep=True).iloc[:, 1:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 标签处理\n",
    "label = test['Normal/Attack'].apply(lambda x: 1 if x in ['Attack', 'A ttack'] else 0)\n",
    "test = test.drop('Normal/Attack', axis=1).copy(deep=True)\n",
    "\n",
    "# 将标签扩展为与 test 相同的维度\n",
    "label = pd.concat([label] * len(test.columns), axis=1)\n",
    "\n",
    "# 删除全为NaN的行，并填充NaN为0\n",
    "train.dropna(how='all', inplace=True); test.dropna(how='all', inplace=True)\t# 删除全为NaN的行\n",
    "train.fillna(0, inplace=True); test.fillna(0, inplace=True)\t# 将NaN替换为0\n",
    "# 确保数据是数值类型\n",
    "train = train.apply(pd.to_numeric, errors='coerce')\n",
    "test = test.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "\n",
    "\n",
    "# 执行归一化\n",
    "train, test, labels = convertNumpy(train), convertNumpy_4(test), convertNumpy_4(label)\n",
    "_, min_a, max_a = normalize3(np.concatenate((train, test), axis=0))\n",
    "train, _, _ = normalize3(train, min_a, max_a)\n",
    "test, _, _ = normalize3(test, min_a, max_a)\n",
    "\n",
    "output_folder = 'processed/SWaT1'\n",
    "print(f\"train.shape: {train.shape}, test.shape: {test.shape}, labels.shape: {labels.shape}\")\n",
    "# 保存数据为.npy文件\n",
    "for file in ['train', 'test', 'labels']:\n",
    "    np.save(os.path.join(output_folder, f'{file}.npy'), eval(file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSM数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (132480, 25), test.shape: (17568, 25), labels.shape: (17568, 25)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def convertNumpy(df):\n",
    "    # 每隔10取一行数据，从第二列开始取值\n",
    "    x = df[df.columns[:]].values[::5, :]\n",
    "    # print(f\"x.shape: {x.shape}\")\n",
    "    min_vals = x.min(axis=0)\n",
    "    max_vals = x.max(axis=0)\n",
    "    return (x - min_vals) / (max_vals - min_vals + 1e-4)  # 归一化，x.ptp(0) = x.max(0) - x.min(0)，添加1e-4防止除0\n",
    "def convertNumpy_4(df):\n",
    "    x = df.iloc[int(len(df)*0.8):, :]\n",
    "    min_vals = x.min(axis=0)\n",
    "    max_vals = x.max(axis=0)\n",
    "    batch_data = (x - min_vals) / (max_vals - min_vals + 1e-4)\n",
    "    # print(f\"batch_data.shape: {batch_data.shape}\")\n",
    "    return batch_data  # Normalized data\n",
    "def normalize3(a, min_a = None, max_a = None):\n",
    "\tif min_a is None: min_a, max_a = np.min(a, axis = 0), np.max(a, axis = 0)\n",
    "\treturn (a - min_a) / (max_a - min_a + 0.0001), min_a, max_a\n",
    "# 读取数据\n",
    "dataset_folder = 'data/PSM'\n",
    "train_df = pd.read_csv(os.path.join(dataset_folder, 'train.csv'))\n",
    "test_df = pd.read_csv(os.path.join(dataset_folder, 'test.csv'))\n",
    "label_df = pd.read_csv(os.path.join(dataset_folder, 'test_label.csv'))\n",
    "\n",
    "train = train_df.copy(deep=True).iloc[:132480, 1:]\n",
    "test = test_df.copy(deep=True).iloc[:87840, 1:]\n",
    "label = label_df.copy(deep=True).iloc[:87840, 1]\n",
    "\n",
    "\n",
    "train.dropna(how='all', inplace=True); test.dropna(how='all', inplace=True)\t# 删除全为NaN的行\n",
    "train.fillna(0, inplace=True); test.fillna(0, inplace=True)\t# 将NaN替换为0\n",
    "\n",
    "_, min_a, max_a = normalize3(np.concatenate((train, test), axis=0))\n",
    "train, _, _ = normalize3(train, min_a, max_a)\n",
    "test, _, _ = normalize3(test, min_a, max_a)\n",
    "\n",
    "\n",
    "# 将标签扩展为与 test 相同的维度\n",
    "label = pd.concat([label] * len(test.columns), axis=1)\n",
    "\n",
    "# train = convertNumpy(train)\n",
    "test, labels = convertNumpy_4(test), convertNumpy_4(label)\n",
    "# labels = label\n",
    "\n",
    "# output_folder = 'data/PSM/npy'\n",
    "output_folder = 'processed/PSM'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "print(f\"train.shape: {train.shape}, test.shape: {test.shape}, labels.shape: {labels.shape}\")\n",
    "# 保存数据为.npy文件\n",
    "for file in ['train', 'test', 'labels']:\n",
    "    np.save(os.path.join(output_folder, f'{file}.npy'), eval(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HVAC数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (6476, 21), test.shape: (1636, 21), labels.shape: (1636, 21)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def convertNumpy(df):\n",
    "    # 每隔10取一行数据，从第二列开始取值\n",
    "    x = df[df.columns[:]].values[::5, :]\n",
    "    # print(f\"x.shape: {x.shape}\")\n",
    "    min_vals = x.min(axis=0)\n",
    "    max_vals = x.max(axis=0)\n",
    "    return (x - min_vals) / (max_vals - min_vals + 1e-4)  # 归一化，x.ptp(0) = x.max(0) - x.min(0)，添加1e-4防止除0\n",
    "def convertNumpy_4(df):\n",
    "    x = df.iloc[int(len(df)*0.8):, :]\n",
    "    min_vals = x.min(axis=0)\n",
    "    max_vals = x.max(axis=0)\n",
    "    batch_data = (x - min_vals) / (max_vals - min_vals + 1e-4)\n",
    "    # print(f\"batch_data.shape: {batch_data.shape}\")\n",
    "    return batch_data  # Normalized data\n",
    "def normalize3(a, min_a = None, max_a = None):\n",
    "\tif min_a is None: min_a, max_a = np.min(a, axis = 0), np.max(a, axis = 0)\n",
    "\treturn (a - min_a) / (max_a - min_a + 0.0001), min_a, max_a\n",
    "\n",
    "# 读取数据\n",
    "dataset_folder = 'data/HVAC'\n",
    "train_df = pd.read_csv(os.path.join(dataset_folder, 'train.csv'))\n",
    "test_df = pd.read_csv(os.path.join(dataset_folder, 'test.csv'))\n",
    "label_df = pd.read_csv(os.path.join(dataset_folder, 'test_label.csv'))\n",
    "# print(f\"train_df.shape: {train_df.shape}, test_df.shape: {test_df.shape}, label_df.shape: {label_df.shape}\")\n",
    "# 处理训练数据和测试数据\n",
    "train = train_df.copy(deep=True).iloc[:, 1:]\n",
    "test = test_df.copy(deep=True).iloc[:, 1:]\n",
    "label = label_df.copy(deep=True)\n",
    "_, min_a, max_a = normalize3(np.concatenate((train, test), axis=0))\n",
    "train, _, _ = normalize3(train, min_a, max_a)\n",
    "test, _, _ = normalize3(test, min_a, max_a)\n",
    "\n",
    "# 确保数据是数值类型\n",
    "# train = train.apply(pd.to_numeric, errors='coerce')\n",
    "# test = test.apply(pd.to_numeric, errors='coerce')\n",
    "# label = label.apply(pd.to_numeric, errors='coerce')\n",
    "# 将标签扩展为与 test 相同的维度\n",
    "label = pd.concat([label] * len(test.columns), axis=1)\n",
    "# train = convertNumpy(train)\n",
    "# test, labels = convertNumpy_4(test), convertNumpy_4(label)\n",
    "\n",
    "labels = label\n",
    "print(f\"train.shape: {train.shape}, test.shape: {test.shape}, labels.shape: {labels.shape}\")\n",
    "output_folder = 'data/HVAC/npy'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "# 保存数据为.npy文件\n",
    "for file in ['train', 'test', 'labels']:\n",
    "    np.save(os.path.join(output_folder, f'{file}.npy'), eval(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELS数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (6865, 17), test.shape: (1786, 17), labels.shape: (1786, 17)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def convertNumpy(df):\n",
    "    # 每隔10取一行数据，从第二列开始取值\n",
    "    x = df[df.columns[:]].values[::5, :]\n",
    "    # print(f\"x.shape: {x.shape}\")\n",
    "    min_vals = x.min(axis=0)\n",
    "    max_vals = x.max(axis=0)\n",
    "    return (x - min_vals) / (max_vals - min_vals + 1e-4)  # 归一化，x.ptp(0) = x.max(0) - x.min(0)，添加1e-4防止除0\n",
    "def convertNumpy_4(df):\n",
    "    x = df.iloc[int(len(df)*0.8):, :]\n",
    "    min_vals = x.min(axis=0)\n",
    "    max_vals = x.max(axis=0)\n",
    "    batch_data = (x - min_vals) / (max_vals - min_vals + 1e-4)\n",
    "    # print(f\"batch_data.shape: {batch_data.shape}\")\n",
    "    return batch_data  # Normalized data\n",
    "def normalize3(a, min_a = None, max_a = None):\n",
    "\tif min_a is None: min_a, max_a = np.min(a, axis = 0), np.max(a, axis = 0)\n",
    "\treturn (a - min_a) / (max_a - min_a + 0.0001), min_a, max_a\n",
    "\n",
    "# 读取数据\n",
    "dataset_folder = 'data/els'\n",
    "train_df = pd.read_csv(os.path.join(dataset_folder, 'train1.csv'))\n",
    "test_df = pd.read_csv(os.path.join(dataset_folder, 'test.csv'))\n",
    "label_df = pd.read_csv(os.path.join(dataset_folder, 'test_label.csv'))\n",
    "# print(f\"train_df.shape: {train_df.shape}, test_df.shape: {test_df.shape}, label_df.shape: {label_df.shape}\")\n",
    "# 处理训练数据和测试数据\n",
    "train = train_df.copy(deep=True).iloc[:, 1:]\n",
    "test = test_df.copy(deep=True).iloc[:, 1:]\n",
    "label = label_df.copy(deep=True)\n",
    "_, min_a, max_a = normalize3(np.concatenate((train, test), axis=0))\n",
    "train, _, _ = normalize3(train, min_a, max_a)\n",
    "test, _, _ = normalize3(test, min_a, max_a)\n",
    "\n",
    "# 确保数据是数值类型\n",
    "# train = train.apply(pd.to_numeric, errors='coerce')\n",
    "# test = test.apply(pd.to_numeric, errors='coerce')\n",
    "# label = label.apply(pd.to_numeric, errors='coerce')\n",
    "# 将标签扩展为与 test 相同的维度\n",
    "label = pd.concat([label] * len(test.columns), axis=1)\n",
    "# train = convertNumpy(train)\n",
    "# test, labels = convertNumpy_4(test), convertNumpy_4(label)\n",
    "labels = label\n",
    "print(f\"train.shape: {train.shape}, test.shape: {test.shape}, labels.shape: {labels.shape}\")\n",
    "output_folder = 'data/els/npy'\n",
    "output_folder = 'processed/els'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "# 保存数据为.npy文件\n",
    "for file in ['train', 'test', 'labels']:\n",
    "    np.save(os.path.join(output_folder, f'{file}.npy'), eval(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hydrogen数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (6770, 98), test.shape: (1786, 98), labels.shape: (1786, 98)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def convertNumpy(df):\n",
    "    # 每隔10取一行数据，从第二列开始取值\n",
    "    x = df[df.columns[:]].values[::5, :]\n",
    "    # print(f\"x.shape: {x.shape}\")\n",
    "    min_vals = x.min(axis=0)\n",
    "    max_vals = x.max(axis=0)\n",
    "    return (x - min_vals) / (max_vals - min_vals + 1e-4)  # 归一化，x.ptp(0) = x.max(0) - x.min(0)，添加1e-4防止除0\n",
    "def convertNumpy_4(df):\n",
    "    x = df.iloc[int(len(df)*0.8):, :]\n",
    "    min_vals = x.min(axis=0)\n",
    "    max_vals = x.max(axis=0)\n",
    "    batch_data = (x - min_vals) / (max_vals - min_vals + 1e-4)\n",
    "    # print(f\"batch_data.shape: {batch_data.shape}\")\n",
    "    return batch_data  # Normalized data\n",
    "def normalize3(a, min_a = None, max_a = None):\n",
    "\tif min_a is None: min_a, max_a = np.min(a, axis = 0), np.max(a, axis = 0)\n",
    "\treturn (a - min_a) / (max_a - min_a + 0.0001), min_a, max_a\n",
    "\n",
    "# 读取数据\n",
    "dataset_folder = 'data/hydrogen'\n",
    "train_df = pd.read_csv(os.path.join(dataset_folder, 'train.csv'))\n",
    "test_df = pd.read_csv(os.path.join(dataset_folder, 'test.csv'))\n",
    "label_df = pd.read_csv(os.path.join(dataset_folder, 'test_label.csv'))\n",
    "# print(f\"train_df.shape: {train_df.shape}, test_df.shape: {test_df.shape}, label_df.shape: {label_df.shape}\")\n",
    "# 处理训练数据和测试数据\n",
    "train = train_df.copy(deep=True).iloc[:, 1:]\n",
    "test = test_df.copy(deep=True).iloc[:, 1:]\n",
    "label = label_df.copy(deep=True)\n",
    "_, min_a, max_a = normalize3(np.concatenate((train, test), axis=0))\n",
    "train, _, _ = normalize3(train, min_a, max_a)\n",
    "test, _, _ = normalize3(test, min_a, max_a)\n",
    "\n",
    "# 确保数据是数值类型\n",
    "# train = train.apply(pd.to_numeric, errors='coerce')\n",
    "# test = test.apply(pd.to_numeric, errors='coerce')\n",
    "# label = label.apply(pd.to_numeric, errors='coerce')\n",
    "# 将标签扩展为与 test 相同的维度\n",
    "label = pd.concat([label] * len(test.columns), axis=1)\n",
    "# train = convertNumpy(train)\n",
    "# test, labels = convertNumpy_4(test), convertNumpy_4(label)\n",
    "\n",
    "labels = label\n",
    "print(f\"train.shape: {train.shape}, test.shape: {test.shape}, labels.shape: {labels.shape}\")\n",
    "output_folder = 'processed/hydrogen'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "# 保存数据为.npy文件\n",
    "for file in ['train', 'test', 'labels']:\n",
    "    np.save(os.path.join(output_folder, f'{file}.npy'), eval(file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tranad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
